{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htruon5/Data-Science-Project-Template/blob/main/categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZVz9kGWSQWr"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    (\"I read The Great Gatsby\", 1, \"The Great Gatsby\"),\n",
        "    (\"Pride and Prejudice is published in 1963\", 1, \"Pride and Prejudice\"),\n",
        "    (\"I love the story of To Kill a Mockingbird\", 1, \"To Kill a Mockingbird\"),\n",
        "    (\"Nineteen Eighty-Four is a dystopian novel\", 1, \"Nineteen Eighty-Four\"),\n",
        "    (\"Moby-Dick is a whaling adventure\", 1, \"Moby-Dick\"),\n",
        "    (\"My favorite book is Brave New World\", 1, \"Brave New World\"),\n",
        "    (\"Jane Eyre is a gothic novel\", 1, \"Jane Eyre\"),\n",
        "    (\"Lord of the Flies depicts the struggle of young boys\", 1, \"Lord of the Flies\"),\n",
        "    (\"Animal Farm is an allegory\", 1, \"Animal Farm\"),\n",
        "    (\"I just finished reading Frankenstein\", 1, \"Frankenstein\"),\n",
        "    (\"Wuthering Heights is a tragic love story\", 1, \"Wuthering Heights\"),\n",
        "    (\"Sense and Sensibility is another Jane Austen novel\", 1, \"Sense and Sensibility\"),\n",
        "    (\"Crime and Punishment is a psychological novel\", 1, \"Crime and Punishment\"),\n",
        "    (\"Great Expectations tells the story of Pip\", 1, \"Great Expectations\"),\n",
        "    (\"Catcher in the Rye is a coming-of-age story\", 1, \"Catcher in the Rye\"),\n",
        "    (\"Of Mice and Men is a classic novella\", 1, \"Of Mice and Men\"),\n",
        "    (\"Don Quixote is an influential novel\", 1, \"Don Quixote\"),\n",
        "    (\"I just bought War and Peace\", 1, \"War and Peace\"),\n",
        "    (\"Ulysses is considered a masterpiece\", 1, \"Ulysses\"),\n",
        "    (\"Les Misérables is a historical novel\", 1, \"Les Misérables\"),\n",
        "    (\"A Tale of Two Cities is set during the French Revolution\", 1, \"A Tale of Two Cities\"),\n",
        "    (\"Little Women is a story of sisterhood\", 1, \"Little Women\"),\n",
        "    (\"I watched the movie adaptation of The Scarlet Letter\", 1, \"The Scarlet Letter\"),\n",
        "    (\"One Hundred Years of Solitude is a magical realism novel\", 1, \"One Hundred Years of Solitude\"),\n",
        "    (\"Dracula is a classic horror novel\", 1, \"Dracula\"),\n",
        "    (\"Fahrenheit 451 warns against censorship\", 1, \"Fahrenheit 451\"),\n",
        "    (\"Heart of Darkness is a thought-provoking novella\", 1, \"Heart of Darkness\"),\n",
        "    (\"The Odyssey is an ancient Greek epic\", 1, \"The Odyssey\"),\n",
        "    (\"A Christmas Carol is a holiday classic\", 1, \"A Christmas Carol\"),\n",
        "    (\"Anna Karenina is a long, complex novel\", 1, \"Anna Karenina\"),\n",
        "    (\"The Iliad is another ancient Greek epic\", 1, \"The Iliad\"),\n",
        "    (\"The Picture of Dorian Gray is a philosophical novel\", 1, \"The Picture of Dorian Gray\"),\n",
        "    (\"I enjoyed The Secret Garden\", 1, \"The Secret Garden\"),\n",
        "    (\"Gulliver's Travels is a satirical novel\", 1, \"Gulliver's Travels\"),\n",
        "    (\"The Old Man and the Sea is a short novel\", 1, \"The Old Man and the Sea\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lower Case vs. Upper Case"
      ],
      "metadata": {
        "id": "NRobwmMTSmZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "capitalized_data = [\n",
        "    (sentence.replace(book_name, book_name.title()), has_book, book_name.title())\n",
        "    for sentence, has_book, book_name in data\n",
        "]\n",
        "\n",
        "with open('capitalized_data.json','w') as f:\n",
        "  json.dump(capitalized_data, f)\n",
        "\n",
        "print(capitalized_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVwVku4-TmtX",
        "outputId": "2927aaa7-2967-49cd-b3ab-7fdf93d11b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I like Piano Sonata No.2 In F Sharp Minor Op.2:1', 1, 'Piano Sonata No.2 In F Sharp Minor Op.2:1'), ('I read The Great Gatsby', 1, 'The Great Gatsby'), ('Pride And Prejudice is published in 1963', 1, 'Pride And Prejudice'), ('I love the story of To Kill A Mockingbird', 1, 'To Kill A Mockingbird'), ('Nineteen Eighty-Four is a dystopian novel', 1, 'Nineteen Eighty-Four'), ('Moby-Dick is a whaling adventure', 1, 'Moby-Dick'), ('My favorite book is Brave New World', 1, 'Brave New World'), ('Jane Eyre is a gothic novel', 1, 'Jane Eyre'), ('Lord Of The Flies depicts the struggle of young boys', 1, 'Lord Of The Flies'), ('Animal Farm is an allegory', 1, 'Animal Farm'), ('I just finished reading Frankenstein', 1, 'Frankenstein'), ('Wuthering Heights is a tragic love story', 1, 'Wuthering Heights'), ('Sense And Sensibility is another Jane Austen novel', 1, 'Sense And Sensibility'), ('Crime And Punishment is a psychological novel', 1, 'Crime And Punishment'), ('Great Expectations tells the story of Pip', 1, 'Great Expectations'), ('Catcher In The Rye is a coming-of-age story', 1, 'Catcher In The Rye'), ('Of Mice And Men is a classic novella', 1, 'Of Mice And Men'), ('Don Quixote is an influential novel', 1, 'Don Quixote'), ('I just bought War And Peace', 1, 'War And Peace'), ('Ulysses is considered a masterpiece', 1, 'Ulysses'), ('Les Misérables is a historical novel', 1, 'Les Misérables'), ('A Tale Of Two Cities is set during the French Revolution', 1, 'A Tale Of Two Cities'), ('Little Women is a story of sisterhood', 1, 'Little Women'), ('I watched the movie adaptation of The Scarlet Letter', 1, 'The Scarlet Letter'), ('One Hundred Years Of Solitude is a magical realism novel', 1, 'One Hundred Years Of Solitude'), ('Dracula is a classic horror novel', 1, 'Dracula'), ('Fahrenheit 451 warns against censorship', 1, 'Fahrenheit 451'), ('Heart Of Darkness is a thought-provoking novella', 1, 'Heart Of Darkness'), ('The Odyssey is an ancient Greek epic', 1, 'The Odyssey'), ('A Christmas Carol is a holiday classic', 1, 'A Christmas Carol'), ('Anna Karenina is a long, complex novel', 1, 'Anna Karenina'), ('The Iliad is another ancient Greek epic', 1, 'The Iliad'), ('The Picture Of Dorian Gray is a philosophical novel', 1, 'The Picture Of Dorian Gray'), ('I enjoyed The Secret Garden', 1, 'The Secret Garden'), (\"Gulliver'S Travels is a satirical novel\", 1, \"Gulliver'S Travels\"), ('The Old Man And The Sea is a short novel', 1, 'The Old Man And The Sea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lowercase_data = [\n",
        "    (sentence.replace(book_name, book_name.lower()), has_book, book_name.lower())\n",
        "    for sentence, has_book, book_name in data\n",
        "]\n",
        "\n",
        "print(lowercase_data)\n",
        "\n",
        "with open('lowercase_data.json','w') as f:\n",
        "  json.dump(lowercase_data, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLgZYuoPT2HU",
        "outputId": "e4652367-0c1f-40e5-ee2d-de201de97190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I like piano sonata no.2 in f sharp minor op.2:1', 1, 'piano sonata no.2 in f sharp minor op.2:1'), ('I read the great gatsby', 1, 'the great gatsby'), ('pride and prejudice is published in 1963', 1, 'pride and prejudice'), ('I love the story of to kill a mockingbird', 1, 'to kill a mockingbird'), ('nineteen eighty-four is a dystopian novel', 1, 'nineteen eighty-four'), ('moby-dick is a whaling adventure', 1, 'moby-dick'), ('My favorite book is brave new world', 1, 'brave new world'), ('jane eyre is a gothic novel', 1, 'jane eyre'), ('lord of the flies depicts the struggle of young boys', 1, 'lord of the flies'), ('animal farm is an allegory', 1, 'animal farm'), ('I just finished reading frankenstein', 1, 'frankenstein'), ('wuthering heights is a tragic love story', 1, 'wuthering heights'), ('sense and sensibility is another Jane Austen novel', 1, 'sense and sensibility'), ('crime and punishment is a psychological novel', 1, 'crime and punishment'), ('great expectations tells the story of Pip', 1, 'great expectations'), ('catcher in the rye is a coming-of-age story', 1, 'catcher in the rye'), ('of mice and men is a classic novella', 1, 'of mice and men'), ('don quixote is an influential novel', 1, 'don quixote'), ('I just bought war and peace', 1, 'war and peace'), ('ulysses is considered a masterpiece', 1, 'ulysses'), ('les misérables is a historical novel', 1, 'les misérables'), ('a tale of two cities is set during the French Revolution', 1, 'a tale of two cities'), ('little women is a story of sisterhood', 1, 'little women'), ('I watched the movie adaptation of the scarlet letter', 1, 'the scarlet letter'), ('one hundred years of solitude is a magical realism novel', 1, 'one hundred years of solitude'), ('dracula is a classic horror novel', 1, 'dracula'), ('fahrenheit 451 warns against censorship', 1, 'fahrenheit 451'), ('heart of darkness is a thought-provoking novella', 1, 'heart of darkness'), ('the odyssey is an ancient Greek epic', 1, 'the odyssey'), ('a christmas carol is a holiday classic', 1, 'a christmas carol'), ('anna karenina is a long, complex novel', 1, 'anna karenina'), ('the iliad is another ancient Greek epic', 1, 'the iliad'), ('the picture of dorian gray is a philosophical novel', 1, 'the picture of dorian gray'), ('I enjoyed the secret garden', 1, 'the secret garden'), (\"gulliver's travels is a satirical novel\", 1, \"gulliver's travels\"), ('the old man and the sea is a short novel', 1, 'the old man and the sea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conventional vs. Non-Conventional\n"
      ],
      "metadata": {
        "id": "lobynmzXShrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')\n",
        "nltk.help.upenn_tagset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9yjvZ0cbvxG",
        "outputId": "6f091e61-758a-45eb-b614-dc51bbc27f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def is_uncon(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    t = pos_tags[0][1]\n",
        "    uncon = t == \"VB\" or t == \"IN\" or t.startswith(\"W\") or t == 'TO' \\\n",
        "    or t == \"VBP\" or t == 'VBZ'or t == 'CC' or t == 'EX'  or t == 'IN' \\\n",
        "    or t == 'LS'\n",
        "    return uncon\n",
        "\n",
        "\n",
        "unconv_data = []\n",
        "conv_data = []\n",
        "\n",
        "for t in data:\n",
        "    if is_uncon(t[2]):\n",
        "        unconv_data.append(t)\n",
        "    else:\n",
        "        conv_data.append(t)\n",
        "\n",
        "print(\"unconv: \",unconv_data)\n",
        "print(\"conv: \",conv_data)\n",
        "\n",
        "with open('unconv_data.json','w') as f:\n",
        "  json.dump(unconv_data, f)\n",
        "\n",
        "with open('conv_data.json','w') as f:\n",
        "  json.dump(conv_data, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtDb60hGVAB_",
        "outputId": "a42fbdf6-c036-4dc3-f5d3-02df610ee3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unconv:  [('I love the story of To Kill a Mockingbird', 1, 'To Kill a Mockingbird'), ('Of Mice and Men is a classic novella', 1, 'Of Mice and Men')]\n",
            "conv:  [('I like Piano Sonata No.2 In F Sharp Minor Op.2:1', 1, 'Piano Sonata No.2 In F Sharp Minor Op.2:1'), ('I read The Great Gatsby', 1, 'The Great Gatsby'), ('Pride and Prejudice is published in 1963', 1, 'Pride and Prejudice'), ('Nineteen Eighty-Four is a dystopian novel', 1, 'Nineteen Eighty-Four'), ('Moby-Dick is a whaling adventure', 1, 'Moby-Dick'), ('My favorite book is Brave New World', 1, 'Brave New World'), ('Jane Eyre is a gothic novel', 1, 'Jane Eyre'), ('Lord of the Flies depicts the struggle of young boys', 1, 'Lord of the Flies'), ('Animal Farm is an allegory', 1, 'Animal Farm'), ('I just finished reading Frankenstein', 1, 'Frankenstein'), ('Wuthering Heights is a tragic love story', 1, 'Wuthering Heights'), ('Sense and Sensibility is another Jane Austen novel', 1, 'Sense and Sensibility'), ('Crime and Punishment is a psychological novel', 1, 'Crime and Punishment'), ('Great Expectations tells the story of Pip', 1, 'Great Expectations'), ('Catcher in the Rye is a coming-of-age story', 1, 'Catcher in the Rye'), ('Don Quixote is an influential novel', 1, 'Don Quixote'), ('I just bought War and Peace', 1, 'War and Peace'), ('Ulysses is considered a masterpiece', 1, 'Ulysses'), ('Les Misérables is a historical novel', 1, 'Les Misérables'), ('A Tale of Two Cities is set during the French Revolution', 1, 'A Tale of Two Cities'), ('Little Women is a story of sisterhood', 1, 'Little Women'), ('I watched the movie adaptation of The Scarlet Letter', 1, 'The Scarlet Letter'), ('One Hundred Years of Solitude is a magical realism novel', 1, 'One Hundred Years of Solitude'), ('Dracula is a classic horror novel', 1, 'Dracula'), ('Fahrenheit 451 warns against censorship', 1, 'Fahrenheit 451'), ('Heart of Darkness is a thought-provoking novella', 1, 'Heart of Darkness'), ('The Odyssey is an ancient Greek epic', 1, 'The Odyssey'), ('A Christmas Carol is a holiday classic', 1, 'A Christmas Carol'), ('Anna Karenina is a long, complex novel', 1, 'Anna Karenina'), ('The Iliad is another ancient Greek epic', 1, 'The Iliad'), ('The Picture of Dorian Gray is a philosophical novel', 1, 'The Picture of Dorian Gray'), ('I enjoyed The Secret Garden', 1, 'The Secret Garden'), (\"Gulliver's Travels is a satirical novel\", 1, \"Gulliver's Travels\"), ('The Old Man and the Sea is a short novel', 1, 'The Old Man and the Sea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(\"One Hundred Years of Solitude\")\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "id": "kfISugtUaD-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New vs. Old"
      ],
      "metadata": {
        "id": "rKnEn5UGSeyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "API_KEY = \"AIzaSyCU2JlD6RnkR4wMsTzdh5vtC0h7TlhgW3A\"\n",
        "def search_google_books(query, api_key):\n",
        "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}&key={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "def get_publication_year(title, api_key):\n",
        "    results = search_google_books(title, api_key)\n",
        "    items = results.get(\"items\", [])\n",
        "    if items:\n",
        "        published_date_str = items[0].get(\"volumeInfo\", {}).get(\"publishedDate\", \"\")\n",
        "        try:\n",
        "            published_date = datetime.strptime(published_date_str, \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            try:\n",
        "                published_date = datetime.strptime(published_date_str, \"%Y\")\n",
        "            except ValueError:\n",
        "                return None\n",
        "        return published_date.year\n",
        "    return None\n",
        "\n",
        "def is_new(book_title, api_key, threshold=120):\n",
        "    publication_year = get_publication_year(book_title, api_key)\n",
        "    # print(publication_year)\n",
        "    if publication_year is None:\n",
        "        return False\n",
        "    current_year = datetime.now().year\n",
        "    return current_year - publication_year <= threshold\n",
        "\n",
        "new_works = []\n",
        "old_works = []\n",
        "\n",
        "for t in data:\n",
        "    if is_new(t[2], API_KEY):\n",
        "        new_works.append(t)\n",
        "    else:\n",
        "        old_works.append(t)\n",
        "\n",
        "print(\"List of new:\", new_works)\n",
        "print(\"List of old:\", old_works)\n",
        "\n",
        "with open('new_works.json','w') as f:\n",
        "  json.dump(new_works, f)\n",
        "\n",
        "with open('old_works.json','w') as f:\n",
        "  json.dump(old_works, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mAclOlOb3yu",
        "outputId": "6ed3d31e-f792-4eb6-e4b2-00b9631d8aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of new: []\n",
            "List of old: [('I like Piano Sonata No.2 In F Sharp Minor Op.2:1', 1, 'Piano Sonata No.2 In F Sharp Minor Op.2:1'), ('I read The Great Gatsby', 1, 'The Great Gatsby'), ('Pride and Prejudice is published in 1963', 1, 'Pride and Prejudice'), ('I love the story of To Kill a Mockingbird', 1, 'To Kill a Mockingbird'), ('Nineteen Eighty-Four is a dystopian novel', 1, 'Nineteen Eighty-Four'), ('Moby-Dick is a whaling adventure', 1, 'Moby-Dick'), ('My favorite book is Brave New World', 1, 'Brave New World'), ('Jane Eyre is a gothic novel', 1, 'Jane Eyre'), ('Lord of the Flies depicts the struggle of young boys', 1, 'Lord of the Flies'), ('Animal Farm is an allegory', 1, 'Animal Farm'), ('I just finished reading Frankenstein', 1, 'Frankenstein'), ('Wuthering Heights is a tragic love story', 1, 'Wuthering Heights'), ('Sense and Sensibility is another Jane Austen novel', 1, 'Sense and Sensibility'), ('Crime and Punishment is a psychological novel', 1, 'Crime and Punishment'), ('Great Expectations tells the story of Pip', 1, 'Great Expectations'), ('Catcher in the Rye is a coming-of-age story', 1, 'Catcher in the Rye'), ('Of Mice and Men is a classic novella', 1, 'Of Mice and Men'), ('Don Quixote is an influential novel', 1, 'Don Quixote'), ('I just bought War and Peace', 1, 'War and Peace'), ('Ulysses is considered a masterpiece', 1, 'Ulysses'), ('Les Misérables is a historical novel', 1, 'Les Misérables'), ('A Tale of Two Cities is set during the French Revolution', 1, 'A Tale of Two Cities'), ('Little Women is a story of sisterhood', 1, 'Little Women'), ('I watched the movie adaptation of The Scarlet Letter', 1, 'The Scarlet Letter'), ('One Hundred Years of Solitude is a magical realism novel', 1, 'One Hundred Years of Solitude'), ('Dracula is a classic horror novel', 1, 'Dracula'), ('Fahrenheit 451 warns against censorship', 1, 'Fahrenheit 451'), ('Heart of Darkness is a thought-provoking novella', 1, 'Heart of Darkness'), ('The Odyssey is an ancient Greek epic', 1, 'The Odyssey'), ('A Christmas Carol is a holiday classic', 1, 'A Christmas Carol'), ('Anna Karenina is a long, complex novel', 1, 'Anna Karenina'), ('The Iliad is another ancient Greek epic', 1, 'The Iliad'), ('The Picture of Dorian Gray is a philosophical novel', 1, 'The Picture of Dorian Gray'), ('I enjoyed The Secret Garden', 1, 'The Secret Garden'), (\"Gulliver's Travels is a satirical novel\", 1, \"Gulliver's Travels\"), ('The Old Man and the Sea is a short novel', 1, 'The Old Man and the Sea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correct vs. Noise"
      ],
      "metadata": {
        "id": "MCLVGQzY2-Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_misspelling(text, error_rate=0.05):\n",
        "    chars = list(text)\n",
        "    ran =  int(len(chars) * error_rate)\n",
        "    num_errors = ran if ran > 0 else 1\n",
        "    \n",
        "    for _ in range(num_errors):\n",
        "        error_position = random.randint(0, len(chars) - 1)\n",
        "        chars[error_position] = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "    \n",
        "    return ''.join(chars)\n",
        "\n",
        "def misspell_sentence_and_book_name(t):\n",
        "    sentence, has_book_name, book_name = t\n",
        "    if has_book_name:\n",
        "        misspelled_book_name = random_misspelling(book_name)\n",
        "        misspelled_sentence = sentence.replace(book_name, misspelled_book_name)\n",
        "        return (misspelled_sentence, has_book_name, misspelled_book_name)\n",
        "    return t\n",
        "\n",
        "misspelled_data = [misspell_sentence_and_book_name(t) for t in data]\n",
        "\n",
        "print(\"Original data:\", data)\n",
        "print(\"Misspelled data:\", misspelled_data)\n",
        "\n",
        "\n",
        "with open('correct_data.json','w') as f:\n",
        "  json.dump(data, f)\n",
        "\n",
        "with open('misspelled_works.json','w') as f:\n",
        "  json.dump(misspelled_data, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjNJyWV_29xr",
        "outputId": "c5614702-eabe-4292-8426-9e207877f54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data: [('I like Piano Sonata No.2 In F Sharp Minor Op.2:1', 1, 'Piano Sonata No.2 In F Sharp Minor Op.2:1'), ('I read The Great Gatsby', 1, 'The Great Gatsby'), ('Pride and Prejudice is published in 1963', 1, 'Pride and Prejudice'), ('I love the story of To Kill a Mockingbird', 1, 'To Kill a Mockingbird'), ('Nineteen Eighty-Four is a dystopian novel', 1, 'Nineteen Eighty-Four'), ('Moby-Dick is a whaling adventure', 1, 'Moby-Dick'), ('My favorite book is Brave New World', 1, 'Brave New World'), ('Jane Eyre is a gothic novel', 1, 'Jane Eyre'), ('Lord of the Flies depicts the struggle of young boys', 1, 'Lord of the Flies'), ('Animal Farm is an allegory', 1, 'Animal Farm'), ('I just finished reading Frankenstein', 1, 'Frankenstein'), ('Wuthering Heights is a tragic love story', 1, 'Wuthering Heights'), ('Sense and Sensibility is another Jane Austen novel', 1, 'Sense and Sensibility'), ('Crime and Punishment is a psychological novel', 1, 'Crime and Punishment'), ('Great Expectations tells the story of Pip', 1, 'Great Expectations'), ('Catcher in the Rye is a coming-of-age story', 1, 'Catcher in the Rye'), ('Of Mice and Men is a classic novella', 1, 'Of Mice and Men'), ('Don Quixote is an influential novel', 1, 'Don Quixote'), ('I just bought War and Peace', 1, 'War and Peace'), ('Ulysses is considered a masterpiece', 1, 'Ulysses'), ('Les Misérables is a historical novel', 1, 'Les Misérables'), ('A Tale of Two Cities is set during the French Revolution', 1, 'A Tale of Two Cities'), ('Little Women is a story of sisterhood', 1, 'Little Women'), ('I watched the movie adaptation of The Scarlet Letter', 1, 'The Scarlet Letter'), ('One Hundred Years of Solitude is a magical realism novel', 1, 'One Hundred Years of Solitude'), ('Dracula is a classic horror novel', 1, 'Dracula'), ('Fahrenheit 451 warns against censorship', 1, 'Fahrenheit 451'), ('Heart of Darkness is a thought-provoking novella', 1, 'Heart of Darkness'), ('The Odyssey is an ancient Greek epic', 1, 'The Odyssey'), ('A Christmas Carol is a holiday classic', 1, 'A Christmas Carol'), ('Anna Karenina is a long, complex novel', 1, 'Anna Karenina'), ('The Iliad is another ancient Greek epic', 1, 'The Iliad'), ('The Picture of Dorian Gray is a philosophical novel', 1, 'The Picture of Dorian Gray'), ('I enjoyed The Secret Garden', 1, 'The Secret Garden'), (\"Gulliver's Travels is a satirical novel\", 1, \"Gulliver's Travels\"), ('The Old Man and the Sea is a short novel', 1, 'The Old Man and the Sea')]\n",
            "Misspelled data: [('I like Piano Sonata No.e In F Sharp Minor Ot.2:1', 1, 'Piano Sonata No.e In F Sharp Minor Ot.2:1'), ('I read Tha Great Gatsby', 1, 'Tha Great Gatsby'), ('Pride ald Prejudice is published in 1963', 1, 'Pride ald Prejudice'), ('I love the story of To eill a Mockingbird', 1, 'To eill a Mockingbird'), ('Nineteen Eighty-Fofr is a dystopian novel', 1, 'Nineteen Eighty-Fofr'), ('Mobn-Dick is a whaling adventure', 1, 'Mobn-Dick'), ('My favorite book is Brave New corld', 1, 'Brave New corld'), ('Jane Exre is a gothic novel', 1, 'Jane Exre'), ('Lord of the flies depicts the struggle of young boys', 1, 'Lord of the flies'), ('Animal Faim is an allegory', 1, 'Animal Faim'), ('I just finished reading Frankdnstein', 1, 'Frankdnstein'), ('Wuthering Heightv is a tragic love story', 1, 'Wuthering Heightv'), ('Senre and Sensibility is another Jane Austen novel', 1, 'Senre and Sensibility'), ('Crimg and Punishment is a psychological novel', 1, 'Crimg and Punishment'), ('Gremt Expectations tells the story of Pip', 1, 'Gremt Expectations'), ('Catchez in the Rye is a coming-of-age story', 1, 'Catchez in the Rye'), ('Of Mice bnd Men is a classic novella', 1, 'Of Mice bnd Men'), ('aon Quixote is an influential novel', 1, 'aon Quixote'), ('I just bought War andxPeace', 1, 'War andxPeace'), ('Ulysaes is considered a masterpiece', 1, 'Ulysaes'), ('LesaMisérables is a historical novel', 1, 'LesaMisérables'), ('AlTale of Two Cities is set during the French Revolution', 1, 'AlTale of Two Cities'), ('Little Wommn is a story of sisterhood', 1, 'Little Wommn'), ('I watched the movie adaptation of The Skarlet Letter', 1, 'The Skarlet Letter'), ('One Hunored Years of Solitude is a magical realism novel', 1, 'One Hunored Years of Solitude'), ('Dracuva is a classic horror novel', 1, 'Dracuva'), ('Fahrenhfit 451 warns against censorship', 1, 'Fahrenhfit 451'), ('Heart or Darkness is a thought-provoking novella', 1, 'Heart or Darkness'), ('TheoOdyssey is an ancient Greek epic', 1, 'TheoOdyssey'), ('A bhristmas Carol is a holiday classic', 1, 'A bhristmas Carol'), ('Anna karenina is a long, complex novel', 1, 'Anna karenina'), ('The Ixiad is another ancient Greek epic', 1, 'The Ixiad'), ('The Picture of Dortan Gray is a philosophical novel', 1, 'The Picture of Dortan Gray'), ('I enjoyed Tne Secret Garden', 1, 'Tne Secret Garden'), (\"julliver's Travels is a satirical novel\", 1, \"julliver's Travels\"), ('The Old Man bnd the Sea is a short novel', 1, 'The Old Man bnd the Sea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Popular vs. Unpopular"
      ],
      "metadata": {
        "id": "QJX3pGhrSvPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"AIzaSyCU2JlD6RnkR4wMsTzdh5vtC0h7TlhgW3A\"\n",
        "SEARCH_ENGINE_ID = \"5749e0767356e4d82\"\n",
        "def search_google(query, api_key, search_engine_id):\n",
        "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={search_engine_id}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "def is_popular(title, api_key, search_engine_id):\n",
        "    results = search_google(title, api_key, search_engine_id)\n",
        "    total_results = int(results.get(\"searchInformation\", {}).get(\"totalResults\", 0))\n",
        "    print(total_results)\n",
        "    return total_results > 2500000\n",
        "\n",
        "pop_data = []\n",
        "unpop_data = []\n",
        "\n",
        "for t in data:\n",
        "    if is_popular(t[2], API_KEY, SEARCH_ENGINE_ID):\n",
        "      pop_data.append(t)\n",
        "    else:\n",
        "      unpop_data.append(t)\n",
        "       \n",
        "\n",
        "print(\"List of popular works:\", pop_data)\n",
        "print(\"List of unpopular works:\", unpop_data)\n",
        "\n",
        "with open('pop_data','w') as f:\n",
        "  json.dump(pop_data, f)\n",
        "\n",
        "with open('unpop_data','w') as f:\n",
        "  json.dump(unpop_data, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFGLOoK7ctDr",
        "outputId": "2d5d43d0-ee06-416d-b76b-cfdd75e7f3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "List of popular works: []\n",
            "List of unpopular works: [('I like Piano Sonata No.2 In F Sharp Minor Op.2:1', 1, 'Piano Sonata No.2 In F Sharp Minor Op.2:1'), ('I read The Great Gatsby', 1, 'The Great Gatsby'), ('Pride and Prejudice is published in 1963', 1, 'Pride and Prejudice'), ('I love the story of To Kill a Mockingbird', 1, 'To Kill a Mockingbird'), ('Nineteen Eighty-Four is a dystopian novel', 1, 'Nineteen Eighty-Four'), ('Moby-Dick is a whaling adventure', 1, 'Moby-Dick'), ('My favorite book is Brave New World', 1, 'Brave New World'), ('Jane Eyre is a gothic novel', 1, 'Jane Eyre'), ('Lord of the Flies depicts the struggle of young boys', 1, 'Lord of the Flies'), ('Animal Farm is an allegory', 1, 'Animal Farm'), ('I just finished reading Frankenstein', 1, 'Frankenstein'), ('Wuthering Heights is a tragic love story', 1, 'Wuthering Heights'), ('Sense and Sensibility is another Jane Austen novel', 1, 'Sense and Sensibility'), ('Crime and Punishment is a psychological novel', 1, 'Crime and Punishment'), ('Great Expectations tells the story of Pip', 1, 'Great Expectations'), ('Catcher in the Rye is a coming-of-age story', 1, 'Catcher in the Rye'), ('Of Mice and Men is a classic novella', 1, 'Of Mice and Men'), ('Don Quixote is an influential novel', 1, 'Don Quixote'), ('I just bought War and Peace', 1, 'War and Peace'), ('Ulysses is considered a masterpiece', 1, 'Ulysses'), ('Les Misérables is a historical novel', 1, 'Les Misérables'), ('A Tale of Two Cities is set during the French Revolution', 1, 'A Tale of Two Cities'), ('Little Women is a story of sisterhood', 1, 'Little Women'), ('I watched the movie adaptation of The Scarlet Letter', 1, 'The Scarlet Letter'), ('One Hundred Years of Solitude is a magical realism novel', 1, 'One Hundred Years of Solitude'), ('Dracula is a classic horror novel', 1, 'Dracula'), ('Fahrenheit 451 warns against censorship', 1, 'Fahrenheit 451'), ('Heart of Darkness is a thought-provoking novella', 1, 'Heart of Darkness'), ('The Odyssey is an ancient Greek epic', 1, 'The Odyssey'), ('A Christmas Carol is a holiday classic', 1, 'A Christmas Carol'), ('Anna Karenina is a long, complex novel', 1, 'Anna Karenina'), ('The Iliad is another ancient Greek epic', 1, 'The Iliad'), ('The Picture of Dorian Gray is a philosophical novel', 1, 'The Picture of Dorian Gray'), ('I enjoyed The Secret Garden', 1, 'The Secret Garden'), (\"Gulliver's Travels is a satirical novel\", 1, \"Gulliver's Travels\"), ('The Old Man and the Sea is a short novel', 1, 'The Old Man and the Sea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHM6riMCj89u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titles of Creative Works and Amazon Comprehend\n",
        "## Introduction and Background\n",
        "\n",
        "### What is Amazon Comprehend?\n",
        "[Amazon Comprehend](https://aws.amazon.com/comprehend/) is a natural language processing (NLP) service that uses machine learning to find insights and relationships in text. It can perform Named Entity Recognition task, identifying and categorizing named entities that appear in the text. (add the picture of here)\n",
        "### What is Named Entity Recognition?\n",
        "\n",
        "Named Entity Recognition (NER) is a NLP subtask that involves identifying and classifying named entities in text into predefined categories, such as organizations, locations and titles. Machine learning models are trained on annotated datasets to extract the entities and predict the labels. NER has a wide range of real-world applications, such as information extraction and content recommendation. Check [this notebook](https://github.com/emory-courses/computational-linguistics/blob/master/docs/named_entity_recognition.ipynb) by Professor Choi from Emory University for more information.\n",
        "\n",
        "### Why Titles of Creative Works are especially interesting?\n",
        "\n",
        "In the literature, titles of creative works (movie/book/song/software names)  are complex named entities (NE) and pose special challenges for named entity recognition (Ashwini and Choi, 2014). These entities can be linguistically complex, emerging, and written informally on on social media. Dealing with complex and ambiguous entities in open domain environments is a challenging NLP task (Meng et al., 2021). Researchers using NER on downstream tasks have also noted that a significant proportion of their errors are due to NER systems failing to recognize complex entities (Luken et al., 2018; Hanselowski et al., 2018).\n",
        "\n",
        "More intuitively, let's look at the following examples to see why recognizing titles of creative works is challenging.\n",
        "\n",
        "- The Great Gatsby: the \"conventional\" named entity; a adjective followed by noun.  \n",
        "\n",
        "- To Kill a Mockingbird: infinitives\n",
        "\n",
        "- Dial M for Murder: imperative clause\n",
        "\n",
        "- 1984: a number\n",
        "\n",
        "- Yours Truly: this book is released in April 2023, which means you, and the model, possibly have not seen it before.\n",
        "\n"
      ],
      "metadata": {
        "id": "KYNVFIZQnsNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis and Significance\n",
        "Based on the literature, we propose the following hypothesis:\n",
        "**When recognizing titles of creative works, the performance of Amazon Comprehend is significantly influenced by capitalization, conventionality of the title’s  linguistics constitute, and the released time of the work.**\n",
        "\n",
        "### The significance of the project\n",
        "The titles of creative works are linguistically complex, innovative, and emerging. The titles can be colloquial or be mentioned in a colloquial setting like social media. They can be gerunds and infinitives rather than traditional noun phrases. New works are released every day. \n",
        "If the performance of Amazon Comprehend is significantly influenced by capitalization, conventionality of the title’s  linguistics constitute, and the released date to recognize these titles, its accuracy and robustness will be limited. \n",
        "After people recognize these limitations and further train Amazon Comprehend, its robustness in an open-world setting can be improved. \n",
        "\n"
      ],
      "metadata": {
        "id": "KBL-xvyizZon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description\n",
        "### Data Collection\n",
        "\n",
        "We use the English Dataset from [MultiCoNER Datasets](https://registry.opendata.aws/multiconer/), a large multilingual dataset for Named Entity Recognition. This dataset is designed to represent contemporary challenges in NER, including low-context scenarios (short and uncased text) and syntactically complex entities like movie titles (Malmasi et al., 2022). It is a 26M token dataset compiled from public resources and contains 36 NE classes. The dataset is the registry of open data on AWS and is managed by Amazon. (add the pie chart here)\n",
        "\n",
        "### Data Quality\n",
        "The researchers evaluated the NER label quality of the dataset. They generated a small random sample of 400 sentences, and assessed the accuracy of NER gold labels, which was measured at 94% accuracy for the english dataset (Malmasi et al., 2022). \n",
        "\n"
      ],
      "metadata": {
        "id": "3DUanW9ezPu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preprocessing\n",
        "Explains the details of data collection and how you managed your data on AWS, including any preparations and transformations. A sufficient amount of data and relevant data for the problem you set out, both in terms of input data to the model and output data from the model.\n",
        "\n",
        "### Entity Extraction\n",
        "Run this to obatin the datset through AWS CLI Access:"
      ],
      "metadata": {
        "id": "SYMbCUcrHLVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 ls --no-sign-request s3://multiconer/multiconer2023/EN-English"
      ],
      "metadata": {
        "id": "QzbLDtHOIC_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We transform the data from ... to ... through the following code. "
      ],
      "metadata": {
        "id": "MNschtcRt5p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('en_train.conll', 'r') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "# start index of all entries\n",
        "row = []\n",
        "for line,index in zip(data,range(len(data))):\n",
        "    if line[0] == '#':\n",
        "        row.append(index)\n",
        "\n",
        "# find entries with \"Work\"\n",
        "row_label = []\n",
        "for index in range(len(row)):\n",
        "    flag = 0\n",
        "    if index<len(row)-1:\n",
        "        for line_num in range(row[index],row[index+1]):\n",
        "            line = data[line_num]\n",
        "            if len(line) > 5:\n",
        "                last = line[-5:-1]\n",
        "                if last == \"Work\":\n",
        "                    flag = 1\n",
        "    row_label.append(flag)\n",
        "\n",
        "row = []\n",
        "for line,index in zip(data,range(len(data))):\n",
        "    if line[0] == '#':\n",
        "        row.append(index)\n",
        "row.append(len(data))\n",
        "\n",
        "entry = []\n",
        "for i in range(len(row)):\n",
        "    temp = []\n",
        "    if i<len(row)-1:\n",
        "        for j in range(row[i]+1,row[i+1]-2):\n",
        "            temp.append(data[j])\n",
        "        entry.append(temp)\n",
        "\n",
        "clean = []\n",
        "for row in entry:\n",
        "    temp = ''\n",
        "    for col in row:\n",
        "        for index in range(len(col)):\n",
        "            if col[index] == '_':\n",
        "                break\n",
        "        temp+=col[:index]\n",
        "    temp = \" \".join(temp.split()).rstrip()\n",
        "    clean.append(temp)\n",
        "\n",
        "cleaned_data = list(zip(clean, row_label))\n",
        "\n",
        "work = []\n",
        "for row in entry:\n",
        "    temp = ''\n",
        "    work_index = []\n",
        "    index = 0\n",
        "    for col in row:\n",
        "        if len(col) > 5:\n",
        "            last = col[-5:-1]\n",
        "            if last == \"Work\":\n",
        "                for index in range(len(col)):\n",
        "                    if col[index] == '_':\n",
        "                        temp+=col[:index]\n",
        "                        temp += \" \"\n",
        "                        break\n",
        "    temp = \" \".join(temp.split()).rstrip()\n",
        "    work.append(temp)\n",
        "\n",
        "cleaned_data = list(zip(clean, row_label, work))\n",
        "\n",
        "capitalized_data = []\n",
        "index = 0\n",
        "for row in cleaned_data:\n",
        "    string = row[0]\n",
        "    label = row[1]\n",
        "    substring = row[2].rstrip()\n",
        "    string = \" \".join(string.split())\n",
        "    substring = \" \".join(substring.split())\n",
        "    if label == 1:\n",
        "        # Find the starting index of the substring in the string\n",
        "        start_index = string.find(substring)\n",
        "        if start_index == -1:\n",
        "            capitalized_data.append((string,label,substring))\n",
        "            continue\n",
        "        # Find the ending index of the substring in the string\n",
        "        end_index = start_index + len(substring)\n",
        "        # Apply titlecase to the substring\n",
        "        titlecased_substring = substring.title()\n",
        "        # Replace the original substring with the titlecased version\n",
        "        new_string = string[:start_index] + titlecased_substring + string[end_index:]\n",
        "        string = new_string\n",
        "    substring = \" \".join(substring.split()).rstrip().title()\n",
        "    capitalized_data.append((string,label,substring))"
      ],
      "metadata": {
        "id": "7nuSqCqxQUi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_data)\n",
        "print(capitalized_data)"
      ],
      "metadata": {
        "id": "NZyV1CkZUMYx",
        "outputId": "9c75def8-631a-4a9f-b8bd-f901c7cfdda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"cleaned_data.json\", \"w\") as f:\n",
        "    json.dump(cleaned_data, f)"
      ],
      "metadata": {
        "id": "_XA1Tzm-SFSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating New Catogories\n",
        "We manipulate and transform the titles in dataset to new categories: Capitalized vs. Lowercase, Conventional vs. Unconventional, Correct vs. Misspelled, Popular vs. Unpopular, New vs. Old. We saved the results to json files. \n",
        "\n"
      ],
      "metadata": {
        "id": "ukAn1_MjIeun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Capitalized vs. Lowercase"
      ],
      "metadata": {
        "id": "3g65YHyFv2tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the file\n",
        "with open('cleaned_data.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# only the data that contains titles\n",
        "data = [tuple(l) for l in data]\n",
        "data = [t for t in data if t[1] == 1]\n",
        "\n",
        "data = data[1:]\n",
        "\n",
        "capitalized_data = [\n",
        "    (sentence.replace(book_name, book_name.title()), has_book, book_name.title())\n",
        "    for sentence, has_book, book_name in data\n",
        "]\n",
        "\n",
        "with open('capitalized_data.json','w') as f:\n",
        "  json.dump(capitalized_data, f)\n",
        "\n",
        "print(capitalized_data)\n",
        "\n",
        "lowercase_data = [\n",
        "    (sentence.replace(book_name, book_name.lower()), has_book, book_name.lower())\n",
        "    for sentence, has_book, book_name in data\n",
        "]\n",
        "\n",
        "print(lowercase_data)\n",
        "\n",
        "with open('lowercase_data.json','w') as f:\n",
        "  json.dump(lowercase_data, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_UWSO228uUMO",
        "outputId": "af67c97b-8b78-4226-9b9b-b5c3bdf132b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c18b326e0f95>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleaned_data.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# only the data that contains titles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cleaned_data.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correct vs. Misspelled"
      ],
      "metadata": {
        "id": "oHlJRSTTu0Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_misspelling(text, error_rate=0.05):\n",
        "    chars = list(text)\n",
        "    ran =  int(len(chars) * error_rate)\n",
        "    num_errors = ran if ran > 0 else 1\n",
        "    \n",
        "    for _ in range(num_errors):\n",
        "        error_position = random.randint(0, len(chars) - 1)\n",
        "        chars[error_position] = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "    \n",
        "    return ''.join(chars)\n",
        "\n",
        "def misspell_sentence_and_book_name(t):\n",
        "    sentence, has_book_name, book_name = t\n",
        "    if has_book_name:\n",
        "        misspelled_book_name = random_misspelling(book_name)\n",
        "        misspelled_sentence = sentence.replace(book_name, misspelled_book_name)\n",
        "        return (misspelled_sentence, has_book_name, misspelled_book_name)\n",
        "    return t\n",
        "\n",
        "misspelled_data = [misspell_sentence_and_book_name(t) for t in data]\n",
        "\n",
        "print(\"Original data:\", data)\n",
        "print(\"Misspelled data:\", misspelled_data)\n",
        "\n",
        "\n",
        "with open('correct_data.json','w') as f:\n",
        "  json.dump(data, f)\n",
        "\n",
        "with open('misspelled_works.json','w') as f:\n",
        "  json.dump(misspelled_data, f)"
      ],
      "metadata": {
        "id": "6mmCFrOIvIuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conventional vs. Unconventional"
      ],
      "metadata": {
        "id": "YmKn_czIu8of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def is_uncon(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    t = pos_tags[0][1]\n",
        "    uncon = t == \"VB\" or t == \"IN\" or t.startswith(\"W\") or t == 'TO' \\\n",
        "    or t == \"VBP\" or t == 'VBZ'or t == 'CC' or t == 'EX'  or t == 'IN' \\\n",
        "    or t == 'LS'\n",
        "    return uncon\n",
        "\n",
        "\n",
        "unconv_data = []\n",
        "conv_data = []\n",
        "\n",
        "for t in data:\n",
        "    if is_uncon(t[2]):\n",
        "        unconv_data.append(t)\n",
        "    else:\n",
        "        conv_data.append(t)\n",
        "\n",
        "print(\"unconv: \",unconv_data)\n",
        "print(\"conv: \",conv_data)\n",
        "\n",
        "with open('unconv_data.json','w') as f:\n",
        "  json.dump(unconv_data, f)\n",
        "\n",
        "with open('conv_data.json','w') as f:\n",
        "  json.dump(conv_data, f)"
      ],
      "metadata": {
        "id": "NcViE2wbQTt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### New vs. Old"
      ],
      "metadata": {
        "id": "EjQgOlAUL-12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "API_KEY = \"AIzaSyCU2JlD6RnkR4wMsTzdh5vtC0h7TlhgW3A\"\n",
        "def search_google_books(query, api_key):\n",
        "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}&key={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "def get_publication_year(title, api_key):\n",
        "    results = search_google_books(title, api_key)\n",
        "    items = results.get(\"items\", [])\n",
        "    if items:\n",
        "        published_date_str = items[0].get(\"volumeInfo\", {}).get(\"publishedDate\", \"\")\n",
        "        try:\n",
        "            published_date = datetime.strptime(published_date_str, \"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            try:\n",
        "                published_date = datetime.strptime(published_date_str, \"%Y\")\n",
        "            except ValueError:\n",
        "                return None\n",
        "        return published_date.year\n",
        "    return None\n",
        "\n",
        "def is_new(book_title, api_key, threshold=120):\n",
        "    publication_year = get_publication_year(book_title, api_key)\n",
        "    # print(publication_year)\n",
        "    if publication_year is None:\n",
        "        return False\n",
        "    current_year = datetime.now().year\n",
        "    return current_year - publication_year <= threshold\n",
        "\n",
        "new_works = []\n",
        "old_works = []\n",
        "\n",
        "for t in data:\n",
        "    if is_new(t[2], API_KEY):\n",
        "        new_works.append(t)\n",
        "    else:\n",
        "        old_works.append(t)\n",
        "\n",
        "print(\"List of new:\", new_works)\n",
        "print(\"List of old:\", old_works)\n",
        "\n",
        "with open('new_works.json','w') as f:\n",
        "  json.dump(new_works, f)\n",
        "\n",
        "with open('old_works.json','w') as f:\n",
        "  json.dump(old_works, f)"
      ],
      "metadata": {
        "id": "Tt9nHqDWvhT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Popular vs. Unpopular"
      ],
      "metadata": {
        "id": "8adrOK4lvUDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = \"AIzaSyCU2JlD6RnkR4wMsTzdh5vtC0h7TlhgW3A\"\n",
        "SEARCH_ENGINE_ID = \"5749e0767356e4d82\"\n",
        "def search_google(query, api_key, search_engine_id):\n",
        "    url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={search_engine_id}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "def is_popular(title, api_key, search_engine_id):\n",
        "    results = search_google(title, api_key, search_engine_id)\n",
        "    total_results = int(results.get(\"searchInformation\", {}).get(\"totalResults\", 0))\n",
        "    print(total_results)\n",
        "    return total_results > 2500000\n",
        "\n",
        "pop_data = []\n",
        "unpop_data = []\n",
        "\n",
        "for t in data:\n",
        "    if is_popular(t[2], API_KEY, SEARCH_ENGINE_ID):\n",
        "      pop_data.append(t)\n",
        "    else:\n",
        "      unpop_data.append(t)\n",
        "       \n",
        "\n",
        "print(\"List of popular works:\", pop_data)\n",
        "print(\"List of unpopular works:\", unpop_data)\n",
        "\n",
        "with open('pop_data','w') as f:\n",
        "  json.dump(pop_data, f)\n",
        "\n",
        "with open('unpop_data','w') as f:\n",
        "  json.dump(unpop_data, f)"
      ],
      "metadata": {
        "id": "q56ejubRvrc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "Malmasi, Shervin, et al. 2022. Semeval-2022 Task 11: Multilingual Complex Named Entity Recognition (Multiconer). Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022).\n",
        "\n",
        "Tao Meng, Anjie Fang, Oleg Rokhlenko, and Shervin Malmasi. 2021. GEMNET: Effective gated gazetteer representations for recognizing complex entities in low-context input. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1499–1512.\n",
        "\n",
        "Sandeep Ashwini and Jinho D Choi. 2014. Targetable named entity recognition in social media. arXiv eprints, pages arXiv–1408.\n",
        "\n",
        "Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar and Oleg Rokhlenko. 2022. MultiCoNER: a Large-scale Multilingual dataset for Complex Named Entity Recognition. \n",
        "Jackson Luken, Nanjiang Jiang, and Marie-Catherine de Marneffe. 2018. QED: A fact verification system for the FEVER shared task. In Proceedings of the First Workshop on Fact Extraction and VERification (FEVER), pages 156–160, Brussels, Belgium. Association for Computational Linguistics.\n",
        "\n",
        "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT (1). Association for Computational Linguistics."
      ],
      "metadata": {
        "id": "mA4wVcgIr94e"
      }
    }
  ]
}